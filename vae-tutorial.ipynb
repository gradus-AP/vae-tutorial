{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変分オートエンコーダ(VAE)\n",
    "\n",
    "- ニューラルネットワークを用いた生成モデルの一種である, 変分オートエンコーダ(Variational Auto Encoder)に関するメモ.\n",
    "- [Kerasのサンプルコード](https://keras.io/examples/generative/vae/)も実行してみた.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 変分オートエンコーダ(VAE)\n",
    "\n",
    "> **Point**<br>\n",
    "> ✅ **変分オートエンコーダ**(VAE)は, ニューラルネットワークを用いた生成モデルの一種. <br>\n",
    "> ✅ VAEは**符号化器**(エンコーダ)と**復号化器**(デコーダ)とそれらの間の**中間層**からなる.<br>\n",
    "> ✅ 画像データなどをVAEに教師なし学習を行うことで, データをよく説明する低次元の潜在パラメータ空間を構成でき, データ生成が可能である.\n",
    "\n",
    "#### 1-1. 構成\n",
    "\n",
    "VAEは以下の3つの層を備えたニューラルネットワークである.\n",
    "- **符号化器**(エンコーダ)：入力データを中間層に送り, 低次元の特徴量に圧縮する. \n",
    "- **中間層**：入力データの特徴を捉えた潜在的なパラメータ空間.\n",
    "- **復号化器**(デコーダ)：中間層のデータを元のデータに戻す.\n",
    "\n",
    "#### 1-2. 生成モデル\n",
    "\n",
    "VAEのデータの生成過程について述べる. はじめにいくつか記号を導入する：\n",
    "\n",
    "- 入力データ $\\underline{x} \\in {\\mathbb R}^d$\n",
    "- 中間層の特徴量ベクトル $\\underline{z} \\in {\\mathbb R}^q$\n",
    "- 符号化器 $F(\\cdot; \\theta)$. 入力データを潜在パラメータに変換する. パラメータ$\\theta$を持つ(NNの重み/バイアス)\n",
    "- 復号化器 $G(\\cdot; \\phi)$. 潜在パラメータを元のデータに復元する. パラメータ$\\phi$を持つ(NNの重み/バイアス)\n",
    "\n",
    "<!-- 標本$X = \\{\\underline{x}^{(1)}, \\ldots, \\underline{x}^{(N)}\\}$プロセスによって生成されると仮定する： -->\n",
    "\n",
    "**データの生成過程**\n",
    "\n",
    "1. 潜在パラメータ$\\underline{z}$の事前分布は多次元標準正規分布${\\mathcal N}(0, I_q)$に従う.\n",
    "2. 出力$\\underline{x}$は潜在パラメータ$\\underline{z}$に依存して次のように確率的に生成される$$\\underline{x} \\vert \\underline{z} \\sim p_\\theta(\\underline{x} \\vert \\underline{z})$$\n",
    "    ※ $p_\\theta$は入力データの性質および計算コストを考慮して適当にモデリングを行う必要がある. VAEではこのモデリングにNNを用いる. \n",
    "\n",
    "入力$\\underline{x}$に対して, 潜在パラメータの事後分布$p_\\theta(\\underline{z}\\vert \\underline{x})$を知ることが目標である. しかし, この分布を直接求めることは困難なため**近似推論**を利用する\n",
    "- 試験分布$q_\\phi(\\underline{z} \\vert \\underline{x})$により$p_\\theta(\\underline{z} \\vert \\underline{x})$を近似(ただし$\\phi$はパラメータである.)\n",
    "- どの程度よく近似されているかの尺度には次の**変分下界**(variational lower bound)(または, **エビデンス下限**(ELBO: evidence lower bound))を用いる：\n",
    "    $$\\mathcal{L}(\\theta, \\phi, \\underline{x}) := \\log{p_\\theta(\\underline{x})} - {\\rm KL}(q_\\phi(\\underline{z}\\vert\\underline{x})||p_\\theta(\\underline{z}\\vert \\underline{x}))$$\n",
    "    ただし, ${\\rm KL}$はカルバック・ライブラー情報量と呼ばれる確率分布同士の近さの尺度であり, 確率密度関数$p, q$に対し次で定義される：\n",
    "    $${\\rm KL}(p || q) :=  \\int p(z) \\log{\\frac{p(z)}{q(z)}}dz.$$\n",
    "\n",
    "近似推論の教えるところは以下の通りである\n",
    "\n",
    "> **近似推論**<br>\n",
    "> 変分下限を最大化する$q_\\phi(\\underline{z}\\vert\\underline{x})$は$p_\\theta(\\underline{z}\\vert \\underline{x})$をよく近似する.\n",
    "\n",
    "**符号化器**\n",
    "\n",
    "VAEでは試験分布$q_\\phi(\\underline{z} \\vert \\underline{x})$として, 次のような多次元正規分布を仮定する：\n",
    "\n",
    "$$\n",
    "q_\\phi(\\underline{z} \\vert \\underline{x}) = {\\mathcal N}(\\underline{\\mu}(\\underline{x}), \\Sigma(\\underline{x}))\n",
    "$$\n",
    "ただしパラメータ\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\underline{\\mu}(\\underline{x}) &= (\\mu_1(\\underline{x}), \\ldots, \\mu_q(\\underline{x}))\\\\\n",
    "\\Sigma(\\underline{x}) &= {\\rm diag}(\\sigma^2_1(\\underline{x}), \\ldots, \\sigma^2_q(\\underline{x}))\n",
    "\\end{align*}\n",
    "$$\n",
    "は, 入力データから符号化器(適当なNNモデル)を用いて計算する. \n",
    "\n",
    "#### 1-3. 変分下限の評価\n",
    "\n",
    "変分下限を以下のように式変形：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, \\phi, \\underline{x}) &= \\log{p_\\theta(\\underline{x})} - {\\rm KL}(q_\\phi(\\underline{z}\\vert\\underline{x})||p_\\theta(\\underline{z}\\vert \\underline{x}))\\\\\n",
    "&= \\log{p_\\theta(\\underline{x})} - \\int q_\\phi(\\underline{z}\\vert\\underline{x}) \\log \\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p_\\theta(\\underline{z}\\vert \\underline{x})} dz\\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}[\\log{p_\\theta(\\underline{x})}] - \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[\\log \\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p_\\theta(\\underline{z}\\vert \\underline{x})}\\Bigr] \\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[\\log{p_\\theta(\\underline{x})} - \\log \\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p_\\theta(\\underline{z}\\vert \\underline{x})}\\Bigr]\\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[- \\log \\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p_\\theta(\\underline{z}\\vert \\underline{x})p_\\theta(\\underline{x})}\\Bigr]\\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[- \\log \\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p_\\theta(\\underline{x}\\vert \\underline{z})p_\\theta(\\underline{z})}\\Bigr]\\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}[\\log{p_\\theta(\\underline{x}\\vert \\underline{z})}] - {\\rm KL}(q_\\phi(\\underline{z}\\vert\\underline{x})||p_\\theta(\\underline{z}))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**第1項の評価**\n",
    "\n",
    "変分下限の第1項は直接評価することが困難なため, モンテカルロ法による近似計算を行う. $\\underline{z}_1, \\ldots, \\underline{z}_M$を分布$q_\\phi(\\underline{z} \\vert \\underline{x})$から発生させた乱数として, \n",
    "$$\n",
    "\\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}[\\log{p_\\theta(\\underline{x}\\vert \\underline{z})}] \\approx \\frac{1}{M} \\sum_{j = 1}^M \\log p_\\theta(\\underline{x}\\vert \\underline{z}_m)\n",
    "$$\n",
    "と近似する.\n",
    "\n",
    "**第2項(KLダイバージェンス)の評価**\n",
    "\n",
    "変分下限の第2項は具体的に書き下すことができる：\n",
    "$$\n",
    "\\begin{align*}\n",
    "{\\rm KL}(q_\\phi(\\underline{z}\\vert\\underline{x})||p_\\theta(\\underline{z})) &= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[\n",
    "    \\log{\\frac{q_\\phi(\\underline{z}\\vert\\underline{x})}{p(z)}}\n",
    "\\Bigr]\\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[\\log{q_\\phi(\\underline{z}\\vert\\underline{x})} \\Bigr] + \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[- \\log{p(z)}\\Bigr]\\\\\n",
    "&= - \\frac{1}{2} (q\\log(2\\pi e) + \\log{|\\Sigma(\\underline{x}) |}) + \\mathbb{E}_{q_\\phi(\\underline{z}\\vert\\underline{x})}\\Bigl[\\frac{q}{2}\\log{(2\\pi)} + \\frac{1}{2} \\underline{z}^\\top \\underline{z}\\Bigr] \\\\\n",
    "&= - \\frac{q}{2} - \\frac{1}{2}\\log{|\\Sigma(\\underline{x})|} + \\frac{1}{2}||\\underline{\\mu}(\\underline{x})||^2_2 + \\frac{1}{2}{\\rm tr}(\\Sigma(\\underline{x}))\\\\\n",
    "&= - \\frac{1}{2} \\sum_{j=1}^q \\{1 + \\log \\sigma_j^2(\\underline{x})- \\mu_j(\\underline{x})^2 - \\sigma_j^2(\\underline{x})\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "上記をまとめて次を得る.\n",
    "\n",
    "> **VAEの目的関数**<br>\n",
    "> 変分下限の推定量(の-1倍)の推定量\n",
    "> $$\n",
    "> - \\mathcal{L}(\\theta, \\phi, \\underline{x}) \\approx {\\rm KL}(q_\\phi(\\underline{z}\\vert\\underline{x})||p_\\theta(\\underline{z})) - \\frac{1}{M} \\sum_{j = 1}^M \\log p_\\theta(\\underline{x}\\vert \\underline{z}_m)$$\n",
    "> に関して最小化するパラメータ$\\phi, \\theta$が求めるべきパラメータである.\n",
    "\n",
    "#### 1-4. 再パラメータ化\n",
    "\n",
    "目的関数$-\\mathcal{L}(\\theta, \\phi, \\underline{x})$の最適化は, 確率的勾配降下を用いて行う. 確率的勾配降下では, 最適化パラメータに関する微分$\\nabla_{\\theta, \\phi}(-\\mathcal{L}(\\theta, \\phi, \\underline{x}))$を書き下す必要がある. ここで「モンテカルロ法に用いる乱数$\\underline{z}_1, \\ldots, \\underline{z}_M \\sim q_\\phi(\\underline{z} \\vert \\underline{x})$たちは, $\\phi$に依存しているため, $\\partial \\underline{z}_i/\\partial \\theta$が微分不可能となってしまう」という問題が生じる.\n",
    "\n",
    "これに対処するのが**再パラメータ化**(reparametrization trick)というアイデアである.\n",
    "\n",
    "> **再パラメータ化**(reparametrization trick)<br>\n",
    "> $\\epsilon_1, \\ldots, \\epsilon_M$を多次元標準正規分布${\\mathcal N}(0, I_q)$からの乱数とする. $q_\\phi(\\underline{z} \\vert \\underline{x})$からの乱数として\n",
    "> $$z_i = \\underline{\\mu}(\\underline{x}) + \\Sigma^{1/2}(\\underline{x})\\odot\\epsilon_i$$\n",
    "> を用いることで, $\\partial \\underline{z}_i/\\partial \\theta$が計算可能になる(ただし, $\\odot$は成分同士の積を表す)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. 手書き数字画像生成(MNISTデータセット)\n",
    "\n",
    "本セクションの内容は, 以下のページのコードサンプルを実行したものです.\n",
    "\n",
    "[Variational AutoEncoder｜Code Example - Keras](https://keras.io/examples/generative/vae/)\n",
    "\n",
    "#### 1. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "潜在パラメータのサンプリング層\n",
    "\n",
    "Args:\n",
    "    [z_mean, z_log_var]: 多次元ガウス分布のハイパーパラメータ\n",
    "\"\"\"\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "encoder層の構築\n",
    "入力データ型: (28, 28, 1) 28*28のグレースケール画像\n",
    "出力データ型:  \n",
    "\"\"\"\n",
    "latent_dim = 2 # 潜在パラメータの次元\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "# 抽出された特徴量x(16次元vect)から, 潜在パラメータのハイパーパラメータ(z_mean, z_log_var)を作る\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x) \n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "# 潜在パラメータをサンプリング\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dencoder層の構築\n",
    "入力データ型: (latent_dim, 1) (潜在パラメータ数)次元ベクトル\n",
    "出力データ型: (None, 28, 28, 1) -> 元の入力データト同じ次元\n",
    "\"\"\"\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=30, batch_size=128);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 画像生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "plot_label_clusters(vae, x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. 音楽への応用のための今後の課題\n",
    "\n",
    "**和音の生成モデルへの応用、および和音の潜在パラメーター空間の可視化**<br>\n",
    "✅ VAEモデルで和音のデータを学習させ, 和音の特徴量を抽出できるか.<br>\n",
    "✅ 和音データの収集方法, どの程度用意する必要があるか? 音楽のジャンル?<br>\n",
    "\n",
    "---\n",
    "\n",
    "### 4. References\n",
    "\n",
    "[梅津・西井・上田(2020) 『スパース回帰分析とパターン認識』講談社サイエンティサイエンティフィック ](https://www.kspub.co.jp/book/detail/5186206.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
